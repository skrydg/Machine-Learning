{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:04:01.744571",
     "start_time": "2016-11-08T20:04:01.732563"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feature_transform as ftr\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "CNT_HEROES = 113\n",
    "EPS = 1e-5\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:34:04.184767",
     "start_time": "2016-11-08T20:34:04.168756"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model(clf, X, y):\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = np.array(y)\n",
    "        \n",
    "    kf = KFold(n = X.shape[0], n_folds=5, random_state=42)\n",
    "    errors = []\n",
    "    params_list = []\n",
    "    cnt = 0\n",
    "    for train_index, test_index in kf:\n",
    "        print(cnt)\n",
    "        cnt += 1\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        err = log_loss(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        errors.append(err)\n",
    "        params_list.append(clf.get_params())\n",
    "    avg_err = np.average(errors)\n",
    "    return avg_err, np.array(errors), params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:04:13.757591",
     "start_time": "2016-11-08T20:04:11.876334"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"./features.csv\", index_col=\"match_id\")\n",
    "features_test = pd.read_csv(\"./features_test.csv\", index_col=\"match_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавляем инфу о винрейтах героев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:04:44.691238",
     "start_time": "2016-11-08T20:04:44.590170"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heroes_wr = pd.read_csv(\"./data/heroes_wr.csv\", delimiter=';')\n",
    "\n",
    "heroes = pd.read_csv(\"./data/dictionaries/heroes.csv\")\n",
    "\n",
    "heroes = pd.merge(heroes, heroes_wr, on=['localized_name'], how='left')\n",
    "\n",
    "heroes = heroes.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:04:47.898381",
     "start_time": "2016-11-08T20:04:47.162886"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features['r1_hero_wr'] = heroes.ix[features.r1_hero.values]['wr'].values\n",
    "features['r2_hero_wr'] = heroes.ix[features.r2_hero.values]['wr'].values\n",
    "features['r3_hero_wr'] = heroes.ix[features.r3_hero.values]['wr'].values\n",
    "features['r4_hero_wr'] = heroes.ix[features.r4_hero.values]['wr'].values\n",
    "features['r5_hero_wr'] = heroes.ix[features.r5_hero.values]['wr'].values\n",
    "\n",
    "\n",
    "features['d1_hero_wr'] = heroes.ix[features.d1_hero.values]['wr'].values\n",
    "features['d2_hero_wr'] = heroes.ix[features.d2_hero.values]['wr'].values\n",
    "features['d3_hero_wr'] = heroes.ix[features.d3_hero.values]['wr'].values\n",
    "features['d4_hero_wr'] = heroes.ix[features.d4_hero.values]['wr'].values\n",
    "features['d5_hero_wr'] = heroes.ix[features.d5_hero.values]['wr'].values\n",
    "\n",
    "radiant_sorted = features[['r1_hero_wr','r2_hero_wr', 'r3_hero_wr', 'r4_hero_wr', 'r5_hero_wr']].values.T\n",
    "radiant_sorted.sort(axis=0)\n",
    "radiant_sorted = radiant_sorted.T\n",
    "features[['r1_hero_wr','r2_hero_wr', 'r3_hero_wr', 'r4_hero_wr', 'r5_hero_wr']] = radiant_sorted\n",
    "\n",
    "dire_sorted = features[['d1_hero_wr','d2_hero_wr', 'd3_hero_wr', 'd4_hero_wr', 'd5_hero_wr']].values.T\n",
    "dire_sorted.sort(axis=0)\n",
    "dire_sorted = dire_sorted.T\n",
    "features[['d1_hero_wr','d2_hero_wr', 'd3_hero_wr', 'd4_hero_wr', 'd5_hero_wr']] = dire_sorted\n",
    "\n",
    "features_test['r1_hero_wr'] = heroes.ix[features_test.r1_hero.values]['wr'].values\n",
    "features_test['r2_hero_wr'] = heroes.ix[features_test.r2_hero.values]['wr'].values\n",
    "features_test['r3_hero_wr'] = heroes.ix[features_test.r3_hero.values]['wr'].values\n",
    "features_test['r4_hero_wr'] = heroes.ix[features_test.r4_hero.values]['wr'].values\n",
    "features_test['r5_hero_wr'] = heroes.ix[features_test.r5_hero.values]['wr'].values\n",
    "\n",
    "\n",
    "features_test['d1_hero_wr'] = heroes.ix[features_test.d1_hero.values]['wr'].values\n",
    "features_test['d2_hero_wr'] = heroes.ix[features_test.d2_hero.values]['wr'].values\n",
    "features_test['d3_hero_wr'] = heroes.ix[features_test.d3_hero.values]['wr'].values\n",
    "features_test['d4_hero_wr'] = heroes.ix[features_test.d4_hero.values]['wr'].values\n",
    "features_test['d5_hero_wr'] = heroes.ix[features_test.d5_hero.values]['wr'].values\n",
    "\n",
    "radiant_sorted = features_test[['r1_hero_wr','r2_hero_wr', 'r3_hero_wr', 'r4_hero_wr', 'r5_hero_wr']].values.T\n",
    "radiant_sorted.sort(axis=0)\n",
    "radiant_sorted = radiant_sorted.T\n",
    "features_test[['r1_hero_wr','r2_hero_wr', 'r3_hero_wr', 'r4_hero_wr', 'r5_hero_wr']] = radiant_sorted\n",
    "\n",
    "dire_sorted = features_test[['d1_hero_wr','d2_hero_wr', 'd3_hero_wr', 'd4_hero_wr', 'd5_hero_wr']].values.T\n",
    "dire_sorted.sort(axis=0)\n",
    "dire_sorted = dire_sorted.T\n",
    "features_test[['d1_hero_wr','d2_hero_wr', 'd3_hero_wr', 'd4_hero_wr', 'd5_hero_wr']] = dire_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Здесь тип фичи добавляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:04:51.111522",
     "start_time": "2016-11-08T20:04:51.042476"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_team_feature(features):\n",
    "    features['diff_gold'] = features['r1_gold']+features['r2_gold']+features['r3_gold']+features['r4_gold']+features['r5_gold']\\\n",
    "                            -features['d1_gold']-features['d2_gold']-features['d3_gold']-features['d4_gold']-features['d5_gold']\n",
    "\n",
    "    features['diff_xp'] = features['r1_xp']+features['r2_xp']+features['r3_xp']+features['r4_xp']+features['r5_xp']\\\n",
    "                            -features['d1_xp']-features['d2_xp']-features['d3_xp']-features['d4_xp']-features['d5_xp']\n",
    "\n",
    "    features['diff_kills'] = features['r1_kills']+features['r2_kills']+features['r3_kills']+features['r4_kills']+features['r5_kills']\\\n",
    "                            -features['d1_kills']-features['d2_kills']-features['d3_kills']-features['d4_kills']-features['d5_kills']\n",
    "\n",
    "    \n",
    "    for what in ['gold', 'xp', 'kills', 'deaths', 'level', 'items', 'lh']:\n",
    "        sum_r = np.ones(features.shape[0]) * 0\n",
    "        sum_d = np.ones(features.shape[0]) * 0\n",
    "        min_r = np.ones(features.shape[0]) * 10000000\n",
    "        min_d = np.ones(features.shape[0]) * 10000000\n",
    "        max_r = np.ones(features.shape[0]) * (-10000000)\n",
    "        max_d = np.ones(features.shape[0]) * (-10000000)\n",
    "        median_d = np.ndarray((features.shape[0], 5))\n",
    "        median_r = np.ndarray((features.shape[0], 5))\n",
    "        \n",
    "        for j in range(5):\n",
    "            sum_r += features['r' + str(j + 1) + '_' + str(what)]\n",
    "            sum_d += features['d' + str(j + 1) + '_' + str(what)]\n",
    "            min_r = np.minimum(min_r, np.array(features['r' + str(j + 1) + '_' + str(what)]))\n",
    "            min_d = np.minimum(min_d, np.array(features['d' + str(j + 1) + '_' + str(what)]))\n",
    "            max_r = np.maximum(max_r, np.array(features['r' + str(j + 1) + '_' + str(what)]))\n",
    "            max_d = np.maximum(max_d, np.array(features['d' + str(j + 1) + '_' + str(what)]))\n",
    "            median_d[:, j] = np.array(features['d' + str(j + 1) + '_' + str(what)])\n",
    "            median_r[:, j] = np.array(features['r' + str(j + 1) + '_' + str(what)])\n",
    "            \n",
    "        var_r = np.ones(features.shape[0]) * 0\n",
    "        var_d = np.ones(features.shape[0]) * 0\n",
    "        \n",
    "        for j in range(5):\n",
    "            var_r += (np.array(features['r' + str(j + 1) + '_' + str(what)]) - sum_r / 5) ** 2\n",
    "            var_d += (np.array(features['d' + str(j + 1) + '_' + str(what)]) - sum_d / 5) ** 2\n",
    "        \n",
    "        var_r = var_r ** (0.5)\n",
    "        var_d = var_d ** (0.5)\n",
    "        \n",
    "        all_sum = sum_r + sum_d\n",
    "        all_sum[all_sum == 0] = 1\n",
    "        features['summ_r_' + str(what)] = sum_r\n",
    "        features['summ_d_' + str(what)] = sum_d\n",
    "        features['mean_' + str(what)] = (sum_r - sum_d) / all_sum\n",
    "        features['min_r_' + str(what)] = min_r\n",
    "        features['min_d_' + str(what)] = min_d\n",
    "        features['max_r_' + str(what)] = max_r\n",
    "        features['max_d_' + str(what)] = max_d\n",
    "        features['var_d_' + str(what)] = var_d\n",
    "        features['var_r_' + str(what)] = var_r\n",
    "        features['median_r_' + str(what)] = np.median(median_r, axis = 1)\n",
    "        features['median_d_' + str(what)] = np.median(median_d, axis = 1)\n",
    "        features['ratio' + str(what)] = sum_r / np.maximum(sum_d, 1)\n",
    "        features['ratio_mean' + str(what)] = var_r / np.maximum(var_d, 1)\n",
    "        \n",
    "    rd = [\"r1_gold\", \"r2_gold\", \"r3_gold\", \"r4_gold\", \"r5_gold\",\n",
    "            \"d1_gold\",\"d2_gold\", \"d3_gold\", \"d4_gold\", \"d5_gold\",\n",
    "     \"r1_xp\", \"r2_xp\", \"r3_xp\", \"r4_xp\", \"r5_xp\",\n",
    "            \"d1_xp\",\"d2_xp\", \"d3_xp\", \"d4_xp\", \"d5_xp\",\n",
    "      \"r1_kills\", \"r2_kills\", \"r3_kills\", \"r4_kills\", \"r5_kills\",\n",
    "            \"d1_kills\",\"d2_kills\", \"d3_kills\", \"d4_kills\", \"d5_kills\",\n",
    "      \"r1_deaths\", \"r2_deaths\", \"r3_deaths\", \"r4_deaths\", \"r5_deaths\",\n",
    "            \"d1_deaths\",\"d2_deaths\", \"d3_deaths\", \"d4_deaths\", \"d5_deaths\",   \n",
    "      \"r1_level\", \"r2_level\", \"r3_level\", \"r4_level\", \"r5_level\",\n",
    "            \"d1_level\",\"d2_level\", \"d3_level\", \"d4_level\", \"d5_level\"\n",
    "      ,\"r1_items\", \"r2_items\", \"r3_items\", \"r4_items\", \"r5_items\",\n",
    "            \"d1_items\",\"d2_items\", \"d3_items\", \"d4_items\", \"d5_items\"\n",
    "        ,\"r1_lh\", \"r2_lh\", \"r3_lh\", \"r4_lh\", \"r5_lh\",\n",
    "            \"d1_lh\",\"d2_lh\", \"d3_lh\", \"d4_lh\", \"d5_lh\"\n",
    "     ]\n",
    "    features = features.drop(rd, axis=1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:04:53.005786",
     "start_time": "2016-11-08T20:04:53.001783"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start_time_to_patch(start_time):\n",
    "    start_time[start_time>1443052800] = 1\n",
    "    start_time[start_time > 1] = 2\n",
    "    return start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:04:54.210592",
     "start_time": "2016-11-08T20:04:53.762291"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = create_team_feature(features)\n",
    "features_test = create_team_feature(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buf = np.array(features['summ_d_gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.61672628 -0.04291252  0.29023141 ..., -0.17095361 -0.2610566\n",
      " -1.04352991]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skrrydg/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/skrrydg/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "stdscaler = StandardScaler()\n",
    "buf = stdscaler.fit_transform(buf)\n",
    "print(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:04:55.208257",
     "start_time": "2016-11-08T20:04:55.202254"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.start_time = start_time_to_patch(features.start_time.values)\n",
    "features_test.start_time = start_time_to_patch(features_test.start_time.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавляем melee или range герой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5c9c3d2be418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mcnt_melee\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdist_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\" melee\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_hero\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mcnt_range\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdist_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\" range\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_hero\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmelee_hero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnt_melee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1977\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'getitem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1978\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m             return self._engine.get_value(s, k,\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/indexes/numeric.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[1;32m    135\u001b[0m         \u001b[0mconvert\u001b[0m \u001b[0ma\u001b[0m \u001b[0mscalar\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dist_features = pd.read_csv('./data/dictionaries/HeroesFeatures.csv', index_col='index')\n",
    "\n",
    "melee_hero = np.ndarray(features.shape[0])\n",
    "range_hero = np.ndarray(features.shape[0])\n",
    "\n",
    "for i, index in enumerate(features.index.values):\n",
    "\n",
    "    cnt_melee = 0\n",
    "    cnt_range = 0\n",
    "    for s in ['r', 'd']:\n",
    "        for j in range(5):\n",
    "            cnt_melee += dist_features[\" melee\"].ix[features[str(s) + str(j + 1) + \"_hero\"][index]]\n",
    "            cnt_range += dist_features[\" range\"].ix[features[str(s) + str(j + 1) + \"_hero\"][index]]\n",
    "    melee_hero[i] = cnt_melee\n",
    "    range_hero[i] = cnt_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features['cnt_melee'] = np.asarray(melee_hero, dtype=float)\n",
    "features['cnt_range'] = np.asarray(range_hero, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:04:57.058491",
     "start_time": "2016-11-08T20:04:57.003454"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2d487c044367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'radiant_win'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1989\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2034\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2035\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2036\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, convert, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   1632\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m                                    convert=True, verify=True)\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   3709\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3710\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 3711\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   3712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3713\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m             new_blocks = self._slice_take_blocks_ax0(indexer,\n\u001b[0;32m-> 3593\u001b[0;31m                                                      fill_tuple=(fill_value,))\n\u001b[0m\u001b[1;32m   3594\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3595\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[1;32m   3671\u001b[0m                     blocks.append(blk.take_nd(blklocs[mgr_locs.indexer],\n\u001b[1;32m   3672\u001b[0m                                               \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3673\u001b[0;31m                                               fill_tuple=None))\n\u001b[0m\u001b[1;32m   3674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3675\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m--> 992\u001b[0;31m                                        allow_fill=False)\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/skrrydg/anaconda3/lib/python3.5/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                  mask_info=mask_info)\n\u001b[1;32m    934\u001b[0m     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = features.columns.intersection(features_test.columns)\n",
    "X_train, y_train = features[c].copy(), features['radiant_win'].copy()\n",
    "X_test = features_test[c].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "заполняем nan-ки по смыслу: фичи с временем -- на макс+1 (тип сделано было после 5 минут игры),\n",
    "                            остальное на -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:05:01.440416",
     "start_time": "2016-11-08T20:05:01.426407"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-020f0aa415c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_blood_team\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_blood_team\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_blood_player1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_blood_player1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_blood_player2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_blood_player2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_blood_team\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_blood_team\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.first_blood_team = X_train.first_blood_team.fillna(-1)\n",
    "X_train.first_blood_player1 = X_train.first_blood_player1.fillna(-1)\n",
    "X_train.first_blood_player2 = X_train.first_blood_player2.fillna(-1)\n",
    "\n",
    "X_test.first_blood_team = X_test.first_blood_team.fillna(-1)\n",
    "X_test.first_blood_player1 = X_test.first_blood_player1.fillna(-1)\n",
    "X_test.first_blood_player2 =X_test.first_blood_player2.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:05:02.593185",
     "start_time": "2016-11-08T20:05:02.555160"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(300 + 1) # 300 -- 5 minutes\n",
    "X_test = X_test.fillna(300 + 1)\n",
    "X_train['is_cour_bought_radiant'] = (X_train.radiant_courier_time < 300)\n",
    "\n",
    "X_train['is_cour_bought_dire'] = (X_train.dire_courier_time < 300)\n",
    "\n",
    "X_test['is_cour_bought_radiant'] = (X_test.radiant_courier_time < 300)\n",
    "\n",
    "X_test['is_cour_bought_dire'] = (X_test.dire_courier_time < 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тут вставил код Сережи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:05:09.162571",
     "start_time": "2016-11-08T20:05:09.129549"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_delete = [\"start_time\"]\n",
    "\n",
    "X_train = X_train.drop(to_delete, axis=1)\n",
    "X_test = X_test.drop(to_delete, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:05:10.097196",
     "start_time": "2016-11-08T20:05:09.986121"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns=['lobby_type', 'first_blood_team', 'first_blood_player1', 'first_blood_player2']) #бинаризуем \n",
    "X_test = pd.get_dummies(X_test, columns=['lobby_type', 'first_blood_team', 'first_blood_player1', 'first_blood_player2']) #бинаризуем "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:05:11.576181",
     "start_time": "2016-11-08T20:05:11.569177"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heroes = pd.read_csv(\"./data/dictionaries/heroes.csv\")\n",
    "\n",
    "heroes_names = heroes[\"localized_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:06:04.069220",
     "start_time": "2016-11-08T20:05:45.239653"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 112)\n",
      "(17177, 112)\n"
     ]
    }
   ],
   "source": [
    "X_train_sack = ftr.sack_of_heroes(X_train, heroes_names)\n",
    "X_test_sack = ftr.sack_of_heroes(X_test, heroes_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:06:12.651950",
     "start_time": "2016-11-08T20:06:12.438807"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdheroes = [\"r1_hero\", \"r2_hero\", \"r3_hero\", \"r4_hero\", \"r5_hero\", \"d1_hero\",\n",
    "            \"d2_hero\", \"d3_hero\", \"d4_hero\", \"d5_hero\"]\n",
    "X_train_sack = X_train_sack.drop(rdheroes, axis=1)\n",
    "X_test_sack = X_test_sack.drop(rdheroes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:06:15.528871",
     "start_time": "2016-11-08T20:06:15.424801"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_sack = X_train_sack.fillna(0)\n",
    "X_test_sack = X_test_sack.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:06:39.848103",
     "start_time": "2016-11-08T20:06:39.762044"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 263)\n"
     ]
    }
   ],
   "source": [
    "X_train_matrix = np.asarray(X_train_sack.as_matrix(), dtype=np.float64)\n",
    "X_test_matrix = np.asarray(X_test_sack.as_matrix(), dtype=np.float64)\n",
    "print(X_train_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кто с кем стоит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heroes_role = pd.read_csv('./dictionaries/HeroesFeatures.csv', index_col='index')\n",
    "\n",
    "list_features = [\"carrie\", \"support\", \"jungler\", \"mider\", \"melee\", \"range\"]\n",
    "prob_of_heroes_role = [{j:0 for j in list_features} for i in range(heroes_role.shape[0] + 1)]\n",
    "for i in range(heroes_role.shape[0]):\n",
    "    for (j, cur_features) in enumerate(list_features):\n",
    "        prob_of_heroes_role[i + 1][cur_features] = heroes_role.iloc[i][j] + random.random() / 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_support_index(ind, pos, prob_of_heroes_role):\n",
    "    prob = np.ndarray((len(ind)))\n",
    "    for i in range(len(ind)):\n",
    "        prob[i] = prob_of_heroes_role[ind[i]]['support']\n",
    "        \n",
    "    buf = copy.deepcopy(ind)\n",
    "    buf_pos = copy.deepcopy(pos)\n",
    "    buf.pop(np.argmax(prob))\n",
    "    buf_pos.pop(np.argmax(prob))\n",
    "    \n",
    "    return (ind[np.argmax(prob)], pos[np.argmax(prob)], buf, buf_pos)\n",
    "\n",
    "def get_support_or_jungler_index(ind, pos, prob_of_heroes_role):\n",
    "    prob_sup = np.ndarray((len(ind)))\n",
    "    prob_jun = np.ndarray((len(ind)))\n",
    "    \n",
    "    for i in range(len(ind)):\n",
    "        prob_sup[i] = prob_of_heroes_role[ind[i]]['support']\n",
    "        prob_jun[i] = prob_of_heroes_role[ind[i]]['jungler']\n",
    "    \n",
    "    buf = copy.deepcopy(ind)\n",
    "    buf_pos = copy.deepcopy(pos)\n",
    "    \n",
    "    if (np.max(prob_sup) > np.max(prob_jun)):\n",
    "        buf.pop(np.argmax(prob_sup))\n",
    "        buf_pos.pop(np.argmax(prob_sup))\n",
    "        return (ind[np.argmax(prob_sup)], pos[np.argmax(prob_sup)], buf, buf_pos)\n",
    "    else:\n",
    "        buf.pop(np.argmax(prob_jun))\n",
    "        buf_pos.pop(np.argmax(prob_jun))\n",
    "        return (ind[np.argmax(prob_jun)], pos[np.argmax(prob_jun)], buf, buf_pos)\n",
    "\n",
    "def get_carrie_index(ind, pos, prob_of_heroes_role):\n",
    "    prob = np.ndarray((len(ind)))\n",
    "    for i in range(len(ind)):\n",
    "        prob[i] = prob_of_heroes_role[ind[i]]['carrie']\n",
    "        \n",
    "    buf = copy.deepcopy(ind)\n",
    "    buf_pos = copy.deepcopy(pos)\n",
    "    buf.pop(np.argmax(prob))\n",
    "    buf_pos.pop(np.argmax(prob))\n",
    "    \n",
    "    return (ind[np.argmax(prob)], pos[np.argmax(prob)], buf, buf_pos)\n",
    "\n",
    "def get_mider_index(ind, pos, prob_of_heroes_role):\n",
    "    prob = np.ndarray((len(ind)))\n",
    "    for i in range(len(ind)):\n",
    "        prob[i] = prob_of_heroes_role[ind[i]]['mider']\n",
    "        \n",
    "    buf = copy.deepcopy(ind)\n",
    "    buf_pos = copy.deepcopy(pos)\n",
    "    buf.pop(np.argmax(prob))\n",
    "    buf_pos.pop(np.argmax(prob))\n",
    "    \n",
    "    return (ind[np.argmax(prob)], pos[np.argmax(prob)], buf, buf_pos)\n",
    "\n",
    "\n",
    "def get_role_for_single_match(X, prob_of_heroes_role, team):\n",
    "    cnt_features = len(prob_of_heroes_role)\n",
    "    ind = [0 for i in range(5)]\n",
    "    pos = [i for i in range(5)]\n",
    "    for i in range(5): # cnt heroes\n",
    "        ind[i] = int(X[team + str(i + 1) + '_hero'])\n",
    "    \n",
    "    \n",
    "    buf = copy.deepcopy(ind)\n",
    "    buf_pos = copy.deepcopy(pos)\n",
    "    (ind_sup, pos_sup, ind, pos) = get_support_index(ind, pos, prob_of_heroes_role);\n",
    "    (ind_sup_or_jun, pos_sup_or_jun, ind, pos) = get_support_or_jungler_index(ind, pos, prob_of_heroes_role);\n",
    "    (ind_carry, pos_carry, ind, pos) = get_carrie_index(ind, pos, prob_of_heroes_role)\n",
    "    (ind_mider, pos_mider, ind, pos) = get_mider_index(ind, pos, prob_of_heroes_role)\n",
    "    ind_hard = ind[0]\n",
    "    pos_hard = pos[0]\n",
    "    \n",
    "    assert(np.array_equal(np.sort(np.array([ind_sup, ind_sup_or_jun, ind_carry, ind_mider, ind_hard])), np.sort(np.array(buf))))\n",
    "    assert(np.array_equal(np.sort(np.array([pos_sup, pos_sup_or_jun, pos_carry, pos_mider, pos_hard])), np.sort(np.array(buf_pos))))\n",
    "    \n",
    "    return (np.array([ind_sup, ind_sup_or_jun, ind_carry, ind_mider, ind_hard]), \n",
    "            np.array([pos_sup, pos_sup_or_jun, pos_carry, pos_mider, pos_hard]))\n",
    "\n",
    "\n",
    "def get_role(X, prob_of_heroes_role, team):\n",
    "    X_role = np.ndarray((X.shape[0], 5), dtype=int)\n",
    "    pos = np.ndarray((X.shape[0], 5), dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        (X_role[i], pos[i]) = get_role_for_single_match(X.iloc[i], prob_of_heroes_role, team)\n",
    "    return (X_role, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_role_r_X, train_pos_r_X) = get_role(features, prob_of_heroes_role, 'r')\n",
    "(train_role_d_X, train_pos_d_X) = get_role(features, prob_of_heroes_role, 'd')\n",
    "\n",
    "(test_role_r_X, test_pos_r_X) = get_role(features_test, prob_of_heroes_role, 'r')\n",
    "(test_role_d_X, test_pos_d_X) = get_role(features_test, prob_of_heroes_role, 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prob_of_win(train_role_r_X, train_role_d_X, prob_radiant_win):\n",
    "    X = np.zeros(train_role_r_X.shape)\n",
    "    for i in range(train_role_r_X.shape[0]):\n",
    "        for j in range(train_role_r_X.shape[1]):\n",
    "            X[i, j] = prob_radiant_win[train_role_r_X[i, j]][train_role_d_X[i, j]]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prob_of_win_with_folds(features, train_role_r_X, train_role_d_X, n_folds = 4):\n",
    "    kf = KFold(n = features.shape[0], n_folds=n_folds, random_state=42)\n",
    "    ans = np.ndarray((features.shape[0], 5))\n",
    "    \n",
    "    for train_index, test_index in kf:\n",
    "        cur_features = features.ix[train_index] \n",
    "        cur_train_role_r_X = train_role_r_X[train_index]\n",
    "        cur_train_role_d_X = train_role_d_X[train_index]\n",
    "        \n",
    "        prob_radiant_win = np.zeros((CNT_HEROES, CNT_HEROES))\n",
    "        cnt_radiant_win = np.zeros((CNT_HEROES, CNT_HEROES))\n",
    "        for i in range(cur_train_role_r_X.shape[0]):\n",
    "            radiant_win = cur_features['radiant_win'].iloc[i]\n",
    "            for j in range(0, 5):\n",
    "                if (radiant_win):\n",
    "                    prob_radiant_win[cur_train_role_r_X[i][j], cur_train_role_d_X[i][j]] += 1\n",
    "                cnt_radiant_win[cur_train_role_r_X[i][j], cur_train_role_d_X[i][j]] += 1\n",
    "\n",
    "        cnt_radiant_win[cnt_radiant_win == 0] = 1\n",
    "        prob_radiant_win /= cnt_radiant_win\n",
    "\n",
    "        \n",
    "        ans[test_index] = get_prob_of_win(train_role_r_X[test_index], train_role_d_X[train_index], prob_radiant_win)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_prob = get_prob_of_win_with_folds(features, train_role_r_X, train_role_d_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get(X, pos_r, pos_d, what):\n",
    "    gold = np.ndarray((X.shape[0], 12))\n",
    "    cnt_bad = 0\n",
    "    for j in range(X.shape[0]):\n",
    "        rad_sum = 0\n",
    "        dire_sum = 0\n",
    "        for i in range(5):\n",
    "            rad_gold = X['r' + str(pos_r[j, i] + 1) +  '_' + str(what)].iloc[j]\n",
    "            dire_gold = X['d' + str(pos_d[j, i] + 1) +  '_' + str(what)].iloc[j]\n",
    "            gold[j, 2 * i] = rad_gold - dire_gold\n",
    "            if (rad_gold + dire_gold < EPS):\n",
    "                gold[j, 2 * i + 1] = 0\n",
    "            else:\n",
    "                gold[j, 2 * i + 1] = (rad_gold - dire_gold) / (rad_gold + dire_gold)\n",
    "            rad_sum += rad_gold\n",
    "            dire_sum += dire_gold\n",
    "        \n",
    "        gold[j, 10] = rad_sum - dire_sum\n",
    "        if (rad_sum + dire_sum == 0):\n",
    "            gold[j, 11] = 0\n",
    "            cnt_bad += 1\n",
    "        else:\n",
    "            gold[j, 11] = (rad_sum - dire_sum) / (rad_sum + dire_sum)\n",
    "    print(cnt_bad)\n",
    "    \n",
    "    gold_in_degre = np.ndarray((gold.shape[0], gold.shape[1] * 3))\n",
    "    for k in range(gold.shape[1]):\n",
    "        for i in range(3):\n",
    "            gold_in_degre[:, k * 3 + i] = gold[:, k] ** (i + 1)\n",
    "    return gold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n",
      "52\n",
      "287\n",
      "52\n",
      "287\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "train_features = pd.read_csv('./features.csv', index_col='match_id')\n",
    "test_features = pd.read_csv('./features_test.csv', index_col='match_id')\n",
    "\n",
    "X_train_gold = get(train_features, train_pos_r_X, train_pos_d_X, \"gold\")\n",
    "X_test_gold = get(test_features, test_pos_r_X, test_pos_d_X, \"gold\")\n",
    "X_train_xp = get(train_features, train_pos_r_X, train_pos_d_X, \"xp\")\n",
    "X_test_xp = get(test_features, test_pos_r_X, test_pos_d_X, \"xp\")\n",
    "X_train_lh = get(train_features, train_pos_r_X, train_pos_d_X, \"lh\")\n",
    "X_test_lh = get(test_features, test_pos_r_X, test_pos_d_X, \"lh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8975\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prob_radiant_win = np.zeros((CNT_HEROES, CNT_HEROES))\n",
    "cnt_radiant_win = np.zeros((CNT_HEROES, CNT_HEROES))\n",
    "for i in range(train_role_r_X.shape[0]):\n",
    "    radiant_win = features['radiant_win'].iloc[i]\n",
    "    for j in range(2, 5):\n",
    "        if (radiant_win):\n",
    "            prob_radiant_win[train_role_r_X[i][j], train_role_d_X[i][j]] += 1\n",
    "        cnt_radiant_win[train_role_r_X[i][j], train_role_d_X[i][j]] += 1\n",
    "        \n",
    "cnt_radiant_win[cnt_radiant_win == 0] = 1\n",
    "prob_radiant_win /= cnt_radiant_win\n",
    "\n",
    "print(np.count_nonzero(cnt_radiant_win[cnt_radiant_win < 10]))\n",
    "\n",
    "X_test_prob = get_prob_of_win(test_role_r_X, test_role_d_X, prob_radiant_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:06:41.173992",
     "start_time": "2016-11-08T20:06:40.745702"
    },
    "collapsed": false
   },
   "source": [
    "# Добавляем синергию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ind_by_name(name):\n",
    "    for i in range(heroes.shape[0]):\n",
    "        if ((heroes.iloc[i][1] == name) | (heroes.iloc[i][2] == name)):\n",
    "            return heroes.iloc[i][0]\n",
    "    print(name)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/synergy.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "name = data['heronames']\n",
    "cnt_heroes = len(name)\n",
    "\n",
    "ind_by_name = {}\n",
    "for cur_name in name:\n",
    "    ind_by_name[cur_name] = get_ind_by_name(cur_name)\n",
    "    \n",
    "synergy_low_skill = np.zeros((CNT_HEROES + 1, CNT_HEROES + 1))\n",
    "synergy_medium_skill = np.zeros((CNT_HEROES + 1, CNT_HEROES + 1))\n",
    "synergy_high_skill = np.zeros((CNT_HEROES + 1, CNT_HEROES + 1))\n",
    "\n",
    "for i in range(cnt_heroes):\n",
    "    for j in range(cnt_heroes):\n",
    "        if (i != j):\n",
    "            ind_i = ind_by_name[name[i]]\n",
    "            ind_j = ind_by_name[name[j]]\n",
    "            assert(~(ind_i is None))\n",
    "            assert(~(ind_j is None))\n",
    "            synergy_low_skill[ind_i, ind_j] = data['win_rates'][i][j][0]\n",
    "            synergy_medium_skill[ind_i, ind_j] = data['win_rates'][i][j][1]\n",
    "            synergy_high_skill[ind_i, ind_j] = data['win_rates'][i][j][2]\n",
    "\n",
    "stdscaler = StandardScaler(with_mean=False)\n",
    "synergy_low_skill = stdscaler.fit_transform(synergy_low_skill)\n",
    "synergy_medium_skill = stdscaler.fit_transform(synergy_medium_skill)\n",
    "synergy_high_skill = stdscaler.fit_transform(synergy_high_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/antisynergy.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "name = data['heronames']\n",
    "cnt_heroes = len(name)\n",
    "\n",
    "    \n",
    "antisynergy_low_skill = np.zeros((CNT_HEROES + 1, CNT_HEROES + 1))\n",
    "antisynergy_medium_skill = np.zeros((CNT_HEROES + 1, CNT_HEROES + 1))\n",
    "antisynergy_high_skill = np.zeros((CNT_HEROES + 1, CNT_HEROES + 1))\n",
    "\n",
    "for i in range(cnt_heroes):\n",
    "    for j in range(cnt_heroes):\n",
    "        if (i != j):\n",
    "            ind_i = ind_by_name[name[i]]\n",
    "            ind_j = ind_by_name[name[j]]\n",
    "            assert(~(ind_i is None))\n",
    "            assert(~(ind_j is None))\n",
    "            antisynergy_low_skill[ind_i, ind_j] = data['adv_rates'][i][j][0]\n",
    "            antisynergy_medium_skill[ind_i, ind_j] = data['adv_rates'][i][j][1]\n",
    "            antisynergy_high_skill[ind_i, ind_j] = data['adv_rates'][i][j][2]\n",
    "            \n",
    "stdscaler = StandardScaler(with_mean=False)\n",
    "antisynergy_low_skill = stdscaler.fit_transform(antisynergy_low_skill)\n",
    "antisynergy_medium_skill = stdscaler.fit_transform(antisynergy_medium_skill)\n",
    "antisynergy_high_skill = stdscaler.fit_transform(antisynergy_high_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_synergy(synergy_cur_skill, team_r, team_d, ind):\n",
    "    row_ind = np.ndarray(2 * len(team_r) * (len(team_r) - 1))\n",
    "    data = np.ndarray(2 * len(team_r) * (len(team_r) - 1))\n",
    "    col_ind = np.ndarray(2 * len(team_r) * (len(team_r) - 1))\n",
    "    cnt = 0\n",
    "    for team in [team_r, team_d]:\n",
    "        for i in team:\n",
    "            for j in team:\n",
    "                if (i != j):\n",
    "                    row_ind[cnt] = ind\n",
    "                    data[cnt] = synergy_cur_skill[i, j]\n",
    "                    col_ind[cnt] = i * CNT_HEROES + j\n",
    "                    cnt += 1\n",
    "    assert(cnt == row_ind.shape[0])\n",
    "    return (data, row_ind, col_ind)\n",
    "\n",
    "def get_antisynergy(antisynergy_cur_skill, team_r, team_d, ind):\n",
    "    row_ind = np.ndarray(len(team_r) ** 2)\n",
    "    data = np.ndarray(len(team_r) ** 2)\n",
    "    col_ind = np.ndarray(len(team_r) ** 2)\n",
    "    cnt = 0\n",
    "    for i in team_r:\n",
    "        for j in team_d:\n",
    "            row_ind[cnt] = ind\n",
    "            data[cnt] = antisynergy_cur_skill[i, j]\n",
    "            col_ind[cnt] = i * CNT_HEROES + j\n",
    "            cnt += 1\n",
    "    assert(cnt == row_ind.shape[0])\n",
    "    return (data, row_ind, col_ind)\n",
    "\n",
    "def get_synergy_for_all_data(features, synergy_per_skill, get_features, len_array):\n",
    "    all_synergy = None\n",
    "    \n",
    "    for synergy_cur_skill in synergy_per_skill:\n",
    "    \n",
    "        data = np.ndarray((features.shape[0], len_array))\n",
    "        row_ind = np.ndarray((features.shape[0], len_array))\n",
    "        col_ind = np.ndarray((features.shape[0], len_array))\n",
    "        \n",
    "        for i, index in enumerate(features.index.values):\n",
    "            team_r = [0,0,0,0,0]\n",
    "            team_d = [0,0,0,0,0]\n",
    "            for j in range(5):\n",
    "                team_r[j] = features['r' + str(j + 1) + \"_hero\"][index]\n",
    "                team_d[j] = features['d' + str(j + 1) + \"_hero\"][index]\n",
    "            data[i], row_ind[i], col_ind[i] =  get_features(synergy_cur_skill, team_r, team_d, i)\n",
    "            if (i % 10000 == 0):\n",
    "                print(i)\n",
    "        synergy = csr_matrix((data.reshape(-1), (row_ind.reshape(-1), col_ind.reshape(-1))), (features.shape[0], CNT_HEROES * CNT_HEROES))\n",
    "        if (all_synergy is None):\n",
    "            all_synergy = synergy\n",
    "        else:\n",
    "            all_synergy = hstack([all_synergy, synergy]).toarray()\n",
    "            \n",
    "    return all_synergy\n",
    "\n",
    "#add all levels skill\n",
    "#sparce_synergy_train = get_synergy_for_all_data(features, [synergy_medium_skill, synergy_high_skill], get_synergy, 2 * 5 * 4) \n",
    "#sparce_antisynergy_train = get_synergy_for_all_data(features, [antisynergy_medium_skill, antisynergy_high_skill], get_antisynergy, 5 * 5)\n",
    "\n",
    "#sparce_synergy_test = get_synergy_for_all_data(features_test, [synergy_medium_skill, synergy_high_skill], get_synergy, 2 * 5 * 4)\n",
    "#sparce_antisynergy_test = get_synergy_for_all_data(features_test, [antisynergy_medium_skill, antisynergy_high_skill], get_antisynergy, 5 * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sum_synergy(synergy_cur_skill, team_r, team_d, ind):\n",
    "    cnt = 0\n",
    "    sum = [0, 0]\n",
    "    for team in [team_r, team_d]:\n",
    "        for i in team:\n",
    "            for j in team:\n",
    "                if (i != j):\n",
    "                    sum[cnt] += synergy_cur_skill[i, j]\n",
    "\n",
    "        cnt += 1\n",
    "        \n",
    "    disp = [0, 0]\n",
    "    cnt = 0\n",
    "    for team in [team_r, team_d]:\n",
    "        for i in team:\n",
    "            for j in team:\n",
    "                if (i != j):\n",
    "                    disp[cnt] += (sum[cnt] / (5 * 4) - synergy_cur_skill[i, j]) ** 2\n",
    "                    \n",
    "        disp[cnt] = disp[cnt] ** 0.5\n",
    "        cnt += 1\n",
    "     \n",
    "    return np.array((sum[0], \n",
    "                    sum[1], \n",
    "                    abs(sum[0] - sum[1]) / max(1, abs(sum[0] + sum[1])),\n",
    "                    disp[0],\n",
    "                    disp[1],\n",
    "                   abs(disp[1] - disp[0]) / max(1, abs(disp[0] + disp[1]))))\n",
    "\n",
    "def get_sum_antisynergy(antisynergy_cur_skill, team_r, team_d, ind):\n",
    "    cnt = 0\n",
    "    sum = 0\n",
    "    for i in team_r:\n",
    "        for j in team_d:\n",
    "            if (i != j):\n",
    "                sum += antisynergy_cur_skill[i, j]\n",
    "\n",
    "        \n",
    "    disp = 0\n",
    "    cnt = 0\n",
    "    for i in team_r:\n",
    "        for j in team_d:\n",
    "            if (i != j):\n",
    "                disp += (sum / (5 * 5) - antisynergy_cur_skill[i, j]) ** 2\n",
    "                    \n",
    "        disp = disp ** 0.5\n",
    "        cnt += 1\n",
    "     \n",
    "    return np.array((sum, \n",
    "                    disp))\n",
    "\n",
    "def get_synergy_for_all_data(features, synergy_per_skill, get_features, CNT_FEATURES):\n",
    "    all_synergy = np.ndarray((features.shape[0], CNT_FEATURES * len(synergy_per_skill)))\n",
    "    \n",
    "    \n",
    "    for ind, synergy_cur_skill in enumerate(synergy_per_skill):\n",
    "        \n",
    "        for i, index in enumerate(features.index.values):\n",
    "            team_r = [0,0,0,0,0]\n",
    "            team_d = [0,0,0,0,0]\n",
    "            for j in range(5):\n",
    "                team_r[j] = features['r' + str(j + 1) + \"_hero\"][index]\n",
    "                team_d[j] = features['d' + str(j + 1) + \"_hero\"][index]\n",
    "            \n",
    "            all_synergy[i, ind * CNT_FEATURES:(ind + 1) * CNT_FEATURES] = get_features(synergy_cur_skill, team_r, team_d, i)\n",
    "            if (i % 10000 == 0):\n",
    "                print(i)\n",
    "        #synergy = csr_matrix((data.reshape(-1), (row_ind.reshape(-1), col_ind.reshape(-1))), (features.shape[0], CNT_HEROES * CNT_HEROES))\n",
    "        #if (all_synergy is None):\n",
    "        #    all_synergy = synergy\n",
    "        #else:\n",
    "        #    all_synergy = hstack([all_synergy, synergy]).toarray()\n",
    "            \n",
    "    return all_synergy\n",
    "\n",
    "#add all levels skill\n",
    "#synergy_train = get_synergy_for_all_data(features, [synergy_low_skill, synergy_medium_skill, synergy_high_skill], get_sum_synergy, 6) \n",
    "#antisynergy_train = get_synergy_for_all_data(features, [antisynergy_low_skill, antisynergy_medium_skill, antisynergy_high_skill], get_sum_antisynergy, 2)\n",
    "\n",
    "#synergy_test = get_synergy_for_all_data(features_test, [synergy_low_skill, synergy_medium_skill, synergy_high_skill], get_sum_synergy, 6)\n",
    "#antisynergy_test = get_synergy_for_all_data(features_test, [antisynergy_low_skill, antisynergy_medium_skill, antisynergy_high_skill], get_sum_antisynergy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 263)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# they are good features\n",
    "X_train_matrix = np.concatenate((X_train_matrix, X_train_gold, X_train_xp, X_train_lh), axis = 1)\n",
    "X_test_matrix = np.concatenate((X_test_matrix, X_test_gold, X_test_xp, X_test_lh), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17177, 299)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_test_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train_matrix_buf = np.concatenate((X_train_matrix, synergy_train), axis=1)\n",
    "#X_test_matrix_buf = np.concatenate((X_test_matrix, synergy_test), axis=1)\n",
    "\n",
    "#X_test_matrix_buf = csr_matrix(hstack((csr_matrix(X_test_matrix_buf), sparce_synergy_test, sparce_antisynergy_test)))\n",
    "#_train_matrix_buf = csr_matrix(hstack((csr_matrix(X_train_matrix_buf), sparce_synergy_train, sparce_antisynergy_train)))\n",
    "#print(X_train_matrix_buf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()\n",
    "X_train_matrix_buf = stdscaler.fit_transform(X_train_matrix)\n",
    "X_test_matrix_buf = stdscaler.fit_transform(X_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 299)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_matrix_buf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Тестируем модель и предсказываем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:06:52.198345",
     "start_time": "2016-11-08T20:06:52.194343"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_clf1 = LogisticRegression(penalty=\"l1\", C=0.077426368268112694, n_jobs=-1)\n",
    "test_clf2 = RandomForestClassifier(n_estimators=10, criterion=\"entropy\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T20:06:54.769063",
     "start_time": "2016-11-08T20:06:54.764058"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clb_clf2 = CalibratedClassifierCV(test_clf2, method=\"sigmoid\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_clf = VotingClassifier([(\"LR\", test_clf1), (\"RF\", test_clf2)], voting=\"soft\",\n",
    "                            weights=[0.85, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.871565420797 [ 0.83349601  0.86358901  0.88737556  0.90182508  0.87154144]\n"
     ]
    }
   ],
   "source": [
    "avg_error, errors, params_list = test_model(test_clf2, (X_train_matrix_buf), (y_train))\n",
    "\n",
    "print(avg_error, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 51393)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_matrix_buf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T18:03:38.639589",
     "start_time": "2016-11-08T18:03:04.838027"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LR', LogisticRegression(C=0.0774263682681127, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))..._jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         voting='soft', weights=[0.85, 0.15])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clf.fit(X_train_matrix_buf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T18:03:48.151947",
     "start_time": "2016-11-08T18:03:47.681626"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans_df = pd.DataFrame(test_clf.predict_proba(X_test_matrix_buf)[:, 1], index=features_test.index, columns=[\"radiant_win\"])\n",
    "\n",
    "ans_df.to_csv(\"ans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 283)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
