{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1. Pandas, метод ближайших соседей и решающие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Мерцалов А.Д.\n",
    "\n",
    "Группа: 317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
    "\n",
    "Данные: http://stat-computing.org/dataexpo/2009/2008.csv.bz2\n",
    "(обратите внимание, что распаковывать этот файл не обязательно — функция `pandas.read_csv` умеет читать из архивов автоматически)\n",
    "\n",
    "Описание: http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "\n",
    "1. Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)\n",
    "2. Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом.\n",
    "3. Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?\n",
    "4. Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?\n",
    "5. Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?\n",
    "6. Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ответы\n",
    "\n",
    "    1) Самая частая причина отмены рейса: weather(54904 штук)\n",
    "    \n",
    "    2) Min: 11, Mean: 726.387029425, Max: 4962\n",
    "    \n",
    "    3) Выглядит подозрительно. Эти рейсы были выполнены 15.05.2008, рейс: 4988 и 10.08.2008, рейс: 5572. Чтобы посмотреть какие расстояния были пройдены этими рейсами в другие дни см. TASK 3 в pandas.ipynb\n",
    "    \n",
    "    4) Аэропорт из которого вылетало больше всего самолетов: William B Hartsfield-Atlanta Intl USA \n",
    "    \n",
    "    5) Среднее время полета по всем вылетевшим из него самолетам: см. TASK 5 в pandas.ipynb. Аэропорт с самым большим показателем времени полета: Luis Munoz Marin International (203.850)\n",
    "    \n",
    "    6) Аэропорт у которого наибольшая доля задержанных рейсов: Dallas Love. Были исключены у которых было меньше 1000 рейсов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "\n",
    "data = pd.read_csv(\"./2008.csv.bz2\", compression='bz2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TASK 1\n",
    "real_reason = {'A': 'carrier', 'B': 'weather', 'C': 'NAS', 'D': 'security'}\n",
    "def get_the_most_frequent(input_array):\n",
    "    buf = copy.deepcopy(input_array)\n",
    "    buf = buf[buf == buf]\n",
    "    buf = np.sort(buf)\n",
    "    \n",
    "    Y = np.concatenate((buf[1:], np.array([np.nan])))\n",
    "    lens_seg = np.cumsum(np.ones(buf.shape[0]))\n",
    "    val = buf[buf != Y]\n",
    "    lens_seg = lens_seg[buf != Y]\n",
    "    lens_seg = np.asarray(np.concatenate((lens_seg[0:1], np.diff(lens_seg))), dtype = int)\n",
    "    ind = np.argmax(lens_seg)\n",
    "    max = lens_seg[ind]\n",
    "    max_value = val[ind]\n",
    "    return (max, max_value)\n",
    "\n",
    "column_cancell = data['CancellationCode']\n",
    "(max, max_reason) = get_the_most_frequent(column_cancell)\n",
    "        \n",
    "print(\"COUNT:\", max)\n",
    "print(\"REASON:\", real_reason[max_reason])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TASK 2\n",
    "column_distance = data['Distance']\n",
    "column_distance = column_distance[column_distance == column_distance]\n",
    "min_distance = np.min(column_distance)\n",
    "mean_distance = np.mean(column_distance)\n",
    "max_distance = np.max(column_distance)\n",
    "\n",
    "print(\"MIN:\", min_distance)\n",
    "print(\"MEAN:\", mean_distance)\n",
    "print(\"MAX:\", max_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TASK 3\n",
    "fly_with_min_dist = data[data['Distance'] == min_distance]\n",
    "\n",
    "idn_flight = []\n",
    "for i in range(fly_with_min_dist.shape[0]):\n",
    "    print(fly_with_min_dist.iloc[i][0:3])\n",
    "    print(fly_with_min_dist.iloc[i]['FlightNum'])\n",
    "    idn_flight.append(fly_with_min_dist.iloc[i]['FlightNum'])\n",
    "    print()\n",
    "\n",
    "#print(name_plane)\n",
    "\n",
    "print(data[(data['FlightNum'] == idn_flight[0]) | (data['FlightNum'] == idn_flight[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airports = pd.read_csv(\"./airports.csv\")\n",
    "#TASK 4\n",
    "origin = data['Origin']\n",
    "(cnt, idn) = get_the_most_frequent(origin)\n",
    "print(airports[airports['iata'] == idn]['airport'])\n",
    "print(airports[airports['iata'] == idn]['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_origin_airports = pd.merge(data, airports, left_on = 'Origin', right_on='iata')\n",
    "#TASK 5\n",
    "stat_by_airports = data_with_origin_airports.groupby(by='airport').mean()\n",
    "print(np.argmax(stat_by_airports['AirTime']))\n",
    "print(np.max(stat_by_airports['AirTime']))\n",
    "print()\n",
    "print(stat_by_airports['AirTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TASK 6\n",
    "data_with_origin_airports['count'] = 1\n",
    "stat_by_airports = data_with_origin_airports.groupby(by='airport').agg({'DepDelay': (lambda x: x[x > 0].shape[0]),\n",
    "                                                                      'count': np.sum})\n",
    "filter_stat = stat_by_airports[stat_by_airports['count'] >= 1000]\n",
    "print(np.argmax(filter_stat['DepDelay'] / filter_stat['count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: метрические методы и категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все дальнейшие эксперименты предлагается проводить на данных соревнования Amazon Employee Access Challenge: https://www.kaggle.com/c/amazon-employee-access-challenge\n",
    "\n",
    "В данной задаче предлагается предсказать, будет ли одобрен запрос сотрудника на получение доступа к тому или иному ресурсу. Все признаки являются категориальными.\n",
    "\n",
    "Для удобства данные можно загрузить по ссылке: https://www.dropbox.com/s/q6fbs1vvhd5kvek/amazon.csv\n",
    "\n",
    "Сразу прочитаем данные и создадим разбиение на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-754d7670787b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amazon.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('amazon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94210992096188473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# доля положительных примеров\n",
    "data.ACTION.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION 2\n",
      "RESOURCE 7518\n",
      "MGR_ID 4243\n",
      "ROLE_ROLLUP_1 128\n",
      "ROLE_ROLLUP_2 177\n",
      "ROLE_DEPTNAME 449\n",
      "ROLE_TITLE 343\n",
      "ROLE_FAMILY_DESC 2358\n",
      "ROLE_FAMILY 67\n",
      "ROLE_CODE 343\n"
     ]
    }
   ],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print (col_name, len(data[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на втором семинаре.\n",
    "\n",
    "Проще всего будет определить метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html), после чего воспользоваться реализацией kNN из sklearn (в этом случае используйте функцию predict_proba). Можно реализовать метод k ближайших соседей и самостоятально — в этом случае учитите, что он должен возвращать оценку вероятности, то есть отношение объектов первого класса среди соседей к числу соседей).\n",
    "\n",
    "Постарайтесь уделить особое внимание эффективности кода — при реализации метрик \"в лоб\" вы можете столкнуться с очень большим временем выполнения.\n",
    "\n",
    "#### Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Мера качества — AUC-ROC.\n",
    "\n",
    "#### Какая функция расстояния оказалась лучшей?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ответы\n",
    "\n",
    "Реализация функций расстояния:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indicator(x, y, **kwargs):\n",
    "    return (np.sum(x != y))\n",
    "\n",
    "def smoothed_indicator(x, y, **kwargs):\n",
    "    buf = kwargs['p_2']\n",
    "    return np.sum((x != y) + (x == y) * buf[:, np.asarray(x, int)])\n",
    "\n",
    "def log_indicator(x, y, **kwargs):\n",
    "    buf = kwargs['log_f']\n",
    "    return np.sum((x != y) * buf[:, np.asarray(x, int)] * buf[:, np.asarray(y, int)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для метрики indicator: AUC: 0.829499015542\n",
    "\n",
    "<img src=\"auc_indicator.png\", width=200, align=left> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для метрики smoothed_indicator: AUC: 0.833989009583\n",
    "\n",
    "<img src=\"smoothed_indicator.png\", width=200, align=left> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для метрики log_indicator: AUC: 0.819376603473\n",
    "\n",
    "<img src=\"log_indicator.png\", width=200, align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лучшие результаты достигнуты на второй метрике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 (бонус). Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какое наилучшее качество удалось получить?\n",
    "\n",
    "Для подбора можно использовать любые средства из sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ответы\n",
    "#### Весь код можно найти в файле: knn_question_1_and_2\n",
    "\n",
    "Для подбора использовалась самописная функция find_optimal_k. K перебиралось от 1 до 15.\n",
    "\n",
    "Для метрики indicator: K = 9, AUC = 0.83094973406339201\n",
    "\n",
    "Для метрики smoothed_indicator: K = 10, AUC = 0.83469194987351925\n",
    "\n",
    "Для метрики log_indicator: K = 9, AUC = 0.82167888343285744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('amazon.csv')\n",
    "\n",
    "max_value = 0\n",
    "for col_name in data.columns:\n",
    "    max_value = max(max_value, np.max(data[col_name]))\n",
    "print(max_value)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "\n",
    "def display_auc(y_true, y_predict):\n",
    "    print(\"AUC:\", sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true))\n",
    "    (fpr, tpr, thresholds) = sklearn.metrics.roc_curve(y_true=y_true, y_score=y_predict)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "\n",
    "def get_auc(y_true, y_predict):\n",
    "    return sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neigh_with_indicator = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm='brute', metric=indicator)\n",
    "neigh_with_indicator.fit(X_train, y_train)\n",
    "y_with_indicator = neigh_with_indicator.predict_proba(X_test)\n",
    "\n",
    "y_with_indicator = y_with_indicator[:, 1]\n",
    "\n",
    "display_auc(y_true = y_test, y_predict = y_with_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_with_count(input_array): # (value, count)\n",
    "    buf = copy.deepcopy(input_array)\n",
    "    buf = buf[buf == buf]\n",
    "    buf = np.sort(buf)\n",
    "    \n",
    "    Y = np.concatenate((buf[1:], np.array([np.nan])))\n",
    "    lens_seg = np.cumsum(np.ones(buf.shape[0]))\n",
    "    val = buf[buf != Y]\n",
    "    lens_seg = lens_seg[buf != Y]\n",
    "    lens_seg = np.asarray(np.concatenate((lens_seg[0:1], np.diff(lens_seg))), dtype = int)\n",
    "    return (val, lens_seg)\n",
    "\n",
    "\n",
    "p_2 = np.zeros((X_train.shape[1], max_value + 1))\n",
    "p = np.zeros((X_train.shape[1], max_value + 1))\n",
    "f = np.zeros((X_train.shape[1], max_value + 1))\n",
    "for col in range(X_train.shape[1]):\n",
    "    (unique_value, count) = unique_with_count(X_train.iloc[:, col])\n",
    "    cur_f = count\n",
    "    cur_p = (count + 0.0) / X_train.shape[0]\n",
    "    cur_p_2 = count * (count - 1.0) / X_train.shape[0] / (X_train.shape[0] - 1)\n",
    "    sum_p_2 = np.zeros(unique_value.shape[0])\n",
    "    for i in range(unique_value.shape[0]):\n",
    "        sum_p_2[i] = np.sum(cur_p_2[cur_p < cur_p[i]])\n",
    "    \n",
    "    f[col][unique_value] = cur_f\n",
    "    p[col][unique_value] = cur_p\n",
    "    p_2[col][unique_value] = sum_p_2\n",
    "    \n",
    "log_f = np.log(f + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smoothed_indicator(x, y, **kwargs):\n",
    "    buf = kwargs['p_2']\n",
    "    return np.sum((x != y) + (x == y) * buf[:, np.asarray(x, int)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#smoothed_indicator\n",
    "neigh_with_smoothed_indicator = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm='brute', metric=smoothed_indicator, \n",
    "                                                                       metric_params={'p_2': p_2})\n",
    "neigh_with_smoothed_indicator.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_with_smoothed_indicator = neigh_with_smoothed_indicator.predict_proba(np.asarray(X_test, int))\n",
    "y_with_smoothed_indicator = y_with_smoothed_indicator[:, 1]\n",
    "\n",
    "display_auc(y_true = y_test, y_predict = y_with_smoothed_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_indicator(x, y, **kwargs):\n",
    "    buf = kwargs['log_f']\n",
    "    return np.sum((x != y) * buf[:, np.asarray(x, int)] * buf[:, np.asarray(y, int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#log_indicator\n",
    "neigh_with_log_indicator = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm='brute', \n",
    "                                                              metric=log_indicator,\n",
    "                                                             metric_params={'log_f': log_f})\n",
    "neigh_with_log_indicator.fit(X_train, y_train)\n",
    "y_with_log_indicator = neigh_with_log_indicator.predict_proba(np.asarray(X_test, int))\n",
    "\n",
    "y_with_log_indicator = y_with_log_indicator[:, 1]\n",
    "display_auc(y_true = y_test, y_predict = y_with_log_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_k(X_train, y_train, X_test, y_test, MAXK, metric, metric_params = None):\n",
    "    MAXK += 1\n",
    "    classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=MAXK, \n",
    "                                                        algorithm='brute', \n",
    "                                                        metric=metric,\n",
    "                                                        metric_params=metric_params)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    nearest_class = classifier.kneighbors(X_test, return_distance=0)\n",
    "    precision = np.ndarray((MAXK, X_test.shape[0], 2))\n",
    "    for ind_object in range(X_test.shape[0]):\n",
    "        histohram = np.zeros(2)\n",
    "        for k in range(0, MAXK):\n",
    "            histohram[y_train.iloc[nearest_class[ind_object][k]]] += 1\n",
    "            precision[k, ind_object] = histohram / (k + 1)\n",
    "    \n",
    "    max_auc = 0.0\n",
    "    max_k = 0;\n",
    "    for k in range(0, MAXK):\n",
    "        y_predict = precision[k, :, 1]\n",
    "        cur_auc = get_auc(y_true = y_test, y_predict = y_predict)\n",
    "        if (cur_auc > max_auc):\n",
    "            max_auc = cur_auc\n",
    "            max_k = k + 1\n",
    "        \n",
    "    return (max_auc, max_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( find_optimal_k(X_train, y_train, X_test, y_test, 15, log_indicator, metric_params={'log_f': log_f}) )\n",
    "print( find_optimal_k(X_train, y_train, X_test, y_test, 15, smoothed_indicator, metric_params={'p_2': p_2}) )\n",
    "print( find_optimal_k(X_train, y_train, X_test, y_test, 15, indicator) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Реализуйте счетчики (http://blogs.technet.com/b/machinelearning/archive/2015/02/17/big-learning-made-easy-with-counts.aspx), которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, каждый категориальный признак нужно заменить на три: \n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "2. Число `successes` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "3. Сглаженное отношение двух предыдущих величин: (`successes` + 1) / (`counts` + 2).\n",
    "\n",
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `successes` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанные по всей обучающей выборке. Реализуйте и такой вариант. Можно использовать $n = 3$.\n",
    "\n",
    "#### Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответы\n",
    "\n",
    "#### Весь код можно найти в файле: knn_question_3\n",
    "\n",
    "Для K = 10, без фолдинга AUC: 0.788718055439\n",
    "\n",
    "<img src=\"without_folding_10.png\", width=200, align=left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для K = 10, c фолдинга AUC: 0.763562263815\n",
    "\n",
    "<img src=\"with_folding_10.png\", width=200, align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В эксперименте без фолдинга лучший результат был достигнут при k = 14 AUC: 0.79678798609179213 \n",
    "\n",
    "В эксперименте c фолдинга лучший результат был достигнут при k = 16 AUC: 0.77708562015813154 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('amazon.csv')\n",
    "\n",
    "max_value = 0\n",
    "for col_name in data.columns:\n",
    "    max_value = max(max_value, np.max(data[col_name]))\n",
    "print(max_value)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "\n",
    "def display_auc(y_true, y_predict):\n",
    "    print(\"AUC:\", sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true))\n",
    "    (fpr, tpr, thresholds) = sklearn.metrics.roc_curve(y_true=y_true, y_score=y_predict)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "\n",
    "def get_auc(y_true, y_predict):\n",
    "    return sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true)\n",
    "\n",
    "def unique_with_count(input_array): # (value, count)\n",
    "    buf = copy.deepcopy(input_array)\n",
    "    buf = buf[buf == buf]\n",
    "    buf = np.sort(buf)\n",
    "    \n",
    "    Y = np.concatenate((buf[1:], np.array([np.nan])))\n",
    "    lens_seg = np.cumsum(np.ones(buf.shape[0]))\n",
    "    val = buf[buf != Y]\n",
    "    lens_seg = lens_seg[buf != Y]\n",
    "    lens_seg = np.asarray(np.concatenate((lens_seg[0:1], np.diff(lens_seg))), dtype = int)\n",
    "    return (val, lens_seg)\n",
    "\n",
    "\n",
    "p_2 = np.zeros((X_train.shape[1], max_value + 1))\n",
    "p = np.zeros((X_train.shape[1], max_value + 1))\n",
    "f = np.zeros((X_train.shape[1], max_value + 1))\n",
    "for col in range(X_train.shape[1]):\n",
    "    (unique_value, count) = unique_with_count(X_train.iloc[:, col])\n",
    "    cur_f = count\n",
    "    cur_p = (count + 0.0) / X_train.shape[0]\n",
    "    cur_p_2 = count * (count - 1.0) / X_train.shape[0] / (X_train.shape[0] - 1)\n",
    "    sum_p_2 = np.zeros(unique_value.shape[0])\n",
    "    for i in range(unique_value.shape[0]):\n",
    "        sum_p_2[i] = np.sum(cur_p_2[cur_p < cur_p[i]])\n",
    "    \n",
    "    f[col][unique_value] = cur_f\n",
    "    p[col][unique_value] = cur_p\n",
    "    p_2[col][unique_value] = sum_p_2\n",
    "    \n",
    "log_f = np.log(f + 1)\n",
    "\n",
    "def find_optimal_k(X_train, y_train, X_test, y_test, MAXK, metric, metric_params = None):\n",
    "    MAXK += 1\n",
    "    classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=MAXK, \n",
    "                                                        algorithm='brute', \n",
    "                                                        metric=metric,\n",
    "                                                        metric_params=metric_params)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    nearest_class = classifier.kneighbors(X_test, return_distance=0)\n",
    "    precision = np.ndarray((MAXK, X_test.shape[0], 2))\n",
    "    for ind_object in range(X_test.shape[0]):\n",
    "        histohram = np.zeros(2)\n",
    "        for k in range(0, MAXK):\n",
    "            histohram[y_train.iloc[nearest_class[ind_object][k]]] += 1\n",
    "            precision[k, ind_object] = histohram / (k + 1)\n",
    "    \n",
    "    max_auc = 0.0\n",
    "    max_k = 0;\n",
    "    for k in range(0, MAXK):\n",
    "        y_predict = precision[k, :, 1]\n",
    "        cur_auc = get_auc(y_true = y_test, y_predict = y_predict)\n",
    "        if (cur_auc > max_auc):\n",
    "            max_auc = cur_auc\n",
    "            max_k = k + 1\n",
    "        \n",
    "    return (max_auc, max_k)\n",
    "\n",
    "def get_count_and_successed(X_train, y_train):\n",
    "    count = [{} for i in range(X_train.shape[1])]\n",
    "    successed = [{} for i in range(X_train.shape[1])]\n",
    "    for col in range(X_train.shape[1]):\n",
    "        value, len = unique_with_count(X_train.iloc[:, col])\n",
    "        \n",
    "        count[col] = {cur_value: 0 for cur_value in value}\n",
    "        successed[col] = {cur_value: 0 for cur_value in value}\n",
    "        for ind in range(X_train.shape[0]):\n",
    "            count[col][X_train.iloc[ind, col]] += 1\n",
    "            successed[col][X_train.iloc[ind, col]] += (y_train.iloc[ind] == 1)\n",
    "        for cur_value in value:\n",
    "            count[col][cur_value] /= y_train.shape[0]\n",
    "            successed[col][cur_value] /= y_train.shape[0]\n",
    "            \n",
    "    return (count, successed)\n",
    "\n",
    "def get_new_features(X, count, successed):\n",
    "    cnt = 0\n",
    "    new_X = np.ndarray((X.shape[0], 3 * X.shape[1]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            new_X[i, 3 * j] = count[j].get(X.iloc[i, j], 0)\n",
    "            new_X[i, 3 * j + 1] = successed[j].get(X.iloc[i, j], 0)\n",
    "            new_X[i, 3 * j + 2] = (new_X[i, 3 * j + 1] + 1) / (new_X[i, 3 * j] + 2)\n",
    "            cnt += new_X[i, 3 * j] == 0;\n",
    "    print(cnt)\n",
    "    return new_X\n",
    "\n",
    "def get_new_features_with_fold(X, y, CNT_FOLDS = 3):\n",
    "    new_X = np.ndarray((X.shape[0], 3 * X.shape[1]))\n",
    "    for i in range(CNT_FOLDS):\n",
    "        ind = np.ndarray(((X.shape[0] + CNT_FOLDS - 1 - i) // CNT_FOLDS), dtype=int)\n",
    "        other_ind = np.ndarray(X.shape[0] - ind.shape[0], dtype=int)\n",
    "        cnt = 0\n",
    "        cnt_other = 0\n",
    "        for j in range(X.shape[0]):\n",
    "            if (j % CNT_FOLDS == i):\n",
    "                ind[cnt] = j\n",
    "                cnt += 1\n",
    "            else:\n",
    "                other_ind[cnt_other] = j\n",
    "                cnt_other += 1\n",
    "\n",
    "        count, successed = get_count_and_successed(X.iloc[other_ind, :], y.iloc[other_ind])\n",
    "        X_chunk_new = get_new_features(X.iloc[ind, :], count, successed)\n",
    "        new_X[ind, :] = X_chunk_new\n",
    "    return new_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count, successed = get_count_and_successed(X_train, y_train)\n",
    "new_X_train = get_new_features(X_train, count, successed)\n",
    "new_X_test = get_new_features(X_test, count, successed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WITHOUT FOLDING\n",
    "neigh = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, \n",
    "                                               algorithm='brute', \n",
    "                                               metric='euclidean')\n",
    "\n",
    "neigh.fit(new_X_train, y_train)\n",
    "\n",
    "\n",
    "y = neigh.predict_proba(new_X_test)\n",
    "y = y[:, 1]\n",
    "\n",
    "display_auc(y_true = y_test, y_predict = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_optimal_k(new_X_train, y_train, new_X_test, y_test, MAXK=15, metric='euclidean') #WITHOUT FOLDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WITH FOLDING\n",
    "CNT_FOLDS = 3\n",
    "new_X_train = get_new_features_with_fold(X_train, y_train, CNT_FOLDS)\n",
    "\n",
    "\n",
    "count, successed = get_count_and_successed(X_train, y_train)\n",
    "new_X_test = get_new_features(X_test, count, successed)\n",
    "\n",
    "\n",
    "neigh = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, \n",
    "                                               algorithm='brute', \n",
    "                                               metric='euclidean')\n",
    "\n",
    "neigh.fit(new_X_train, y_train)\n",
    "\n",
    "\n",
    "y = neigh.predict_proba(new_X_test)\n",
    "y = y[:, 1]\n",
    "\n",
    "display_auc(y_true = y_test, y_predict = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_optimal_k(new_X_train, y_train, new_X_test, y_test, MAXK=30, metric='euclidean') #WITH FOLDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавьте в исходную выборку парные признаки — то есть для каждой пары $(f_i, f_j)$, $i < j$ исходных категориальных признаков добавьте новый категориальный признак $f_{ij}$, значение которого является конкатенацией значений $f_i$ и $f_j$ (желательно через какой-нибудь специальный символ во избежание коллизий). Посчитайте счетчики для этой выборки, найдите качество метода $k$ ближайших соседей с наилучшим $k$ (с фолдингом и без)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответы\n",
    "\n",
    "Эксперимент с фолдингом:\n",
    "\n",
    "\n",
    "При К = 10 AUC: 0.786943587222\n",
    "\n",
    "<img src=\"with_folding_with_pair_features.png\", width=200, align=left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эксперимент без фолдинга:\n",
    "\n",
    "При К = 10 AUC: 0.80338239808\n",
    "\n",
    "<img src=\"without_folding_with_pair_features.png\", width=200, align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('amazon.csv')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "\n",
    "max_value = 0\n",
    "for col_name in data.columns:\n",
    "    max_value = max(max_value, np.max(data[col_name]))\n",
    "print(max_value)\n",
    "\n",
    "def get_pair_features(X):\n",
    "    print(\"Begin\")\n",
    "    X_new = np.ndarray((X.shape[0], X.shape[1] * (X.shape[1] + 1) // 2))\n",
    "    X_new[:, 0:X.shape[1]] = copy.deepcopy(X.iloc[:])\n",
    "    print(\"End copy\")\n",
    "    len = X.shape[1]\n",
    "    for i in range(X.shape[1]):\n",
    "        print(\"Processing\", i, \"features\")\n",
    "        for j in range(i + 1, X.shape[1]):\n",
    "            for k in range(X.shape[0]):\n",
    "                X_new[k, len] = str(X.iloc[k, i]) + \"0123321\" + str(X.iloc[k, j])\n",
    "            len += 1\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_with_pair_features = get_pair_features(X_train)\n",
    "X_test_with_pair_features = get_pair_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_features(X, count, successed):\n",
    "    cnt = 0\n",
    "    new_X = np.ndarray((X.shape[0], 3 * X.shape[1]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            new_X[i, 3 * j] = count[j].get(X[i, j], 0)\n",
    "            new_X[i, 3 * j + 1] = successed[j].get(X[i, j], 0)\n",
    "            new_X[i, 3 * j + 2] = (new_X[i, 3 * j + 1] + 1) / (new_X[i, 3 * j] + 2)\n",
    "            cnt += new_X[i, 3 * j] == 0;\n",
    "    print(cnt)\n",
    "    return new_X\n",
    "\n",
    "def get_count_and_successed(X_train, y_train):\n",
    "    count = [{} for i in range(X_train.shape[1])]\n",
    "    successed = [{} for i in range(X_train.shape[1])]\n",
    "    for col in range(X_train.shape[1]):\n",
    "        value, len = unique_with_count(X_train[:, col])\n",
    "        \n",
    "        count[col] = {cur_value: 0 for cur_value in value}\n",
    "        successed[col] = {cur_value: 0 for cur_value in value}\n",
    "        for ind in range(X_train.shape[0]):\n",
    "            count[col][X_train[ind, col]] += 1\n",
    "            successed[col][X_train[ind, col]] += (y_train[ind] == 1)\n",
    "        for cur_value in value:\n",
    "            count[col][cur_value] /= y_train.shape[0]\n",
    "            successed[col][cur_value] /= y_train.shape[0]\n",
    "            \n",
    "    return (count, successed)\n",
    "\n",
    "def unique_with_count(input_array): # (value, count)\n",
    "    buf = copy.deepcopy(input_array)\n",
    "    buf = buf[buf == buf]\n",
    "    buf = np.sort(buf)\n",
    "    \n",
    "    Y = np.concatenate((buf[1:], np.array([np.nan])))\n",
    "    lens_seg = np.cumsum(np.ones(buf.shape[0]))\n",
    "    val = buf[buf != Y]\n",
    "    lens_seg = lens_seg[buf != Y]\n",
    "    lens_seg = np.asarray(np.concatenate((lens_seg[0:1], np.diff(lens_seg))), dtype = int)\n",
    "    return (val, lens_seg)\n",
    "\n",
    "\n",
    "p_2 = np.zeros((X_train.shape[1], max_value + 1))\n",
    "p = np.zeros((X_train.shape[1], max_value + 1))\n",
    "f = np.zeros((X_train.shape[1], max_value + 1))\n",
    "for col in range(X_train.shape[1]):\n",
    "    (unique_value, count) = unique_with_count(X_train.iloc[:, col])\n",
    "    cur_f = count\n",
    "    cur_p = (count + 0.0) / X_train.shape[0]\n",
    "    cur_p_2 = count * (count - 1.0) / X_train.shape[0] / (X_train.shape[0] - 1)\n",
    "    sum_p_2 = np.zeros(unique_value.shape[0])\n",
    "    for i in range(unique_value.shape[0]):\n",
    "        sum_p_2[i] = np.sum(cur_p_2[cur_p < cur_p[i]])\n",
    "    \n",
    "    f[col][unique_value] = cur_f\n",
    "    p[col][unique_value] = cur_p\n",
    "    p_2[col][unique_value] = sum_p_2\n",
    "    \n",
    "log_f = np.log(f + 1)\n",
    "\n",
    "def display_auc(y_true, y_predict):\n",
    "    print(\"AUC:\", sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true))\n",
    "    (fpr, tpr, thresholds) = sklearn.metrics.roc_curve(y_true=y_true, y_score=y_predict)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "\n",
    "def get_auc(y_true, y_predict):\n",
    "    return sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count, successed = get_count_and_successed(X_train_with_pair_features, np.array(y_train.iloc[:], dtype=int))\n",
    "new_X_train_with_pair_features = get_new_features(X_train_with_pair_features, count, successed)\n",
    "new_X_test_with_pair_features = get_new_features(X_test_with_pair_features, count, successed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_k(X_train, y_train, X_test, y_test, MAXK, metric, metric_params = None):\n",
    "    MAXK += 1\n",
    "    classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=MAXK, \n",
    "                                                        algorithm='brute', \n",
    "                                                        metric=metric,\n",
    "                                                        metric_params=metric_params)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    nearest_class = classifier.kneighbors(X_test, return_distance=0)\n",
    "    precision = np.ndarray((MAXK, X_test.shape[0], 2))\n",
    "    for ind_object in range(X_test.shape[0]):\n",
    "        histohram = np.zeros(2)\n",
    "        for k in range(0, MAXK):\n",
    "            histohram[y_train.iloc[nearest_class[ind_object][k]]] += 1\n",
    "            precision[k, ind_object] = histohram / (k + 1)\n",
    "    \n",
    "    max_auc = 0.0\n",
    "    max_k = 0;\n",
    "    max_y = None\n",
    "    for k in range(0, MAXK):\n",
    "        y_predict = precision[k, :, 1]\n",
    "        cur_auc = get_auc(y_true = y_test, y_predict = y_predict)\n",
    "        if (cur_auc > max_auc):\n",
    "            max_auc = cur_auc\n",
    "            max_k = k + 1\n",
    "            max_y = y_predict\n",
    "            \n",
    "    display_auc(y_true=y_test, y_predict=max_y)\n",
    "    return (max_auc, max_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WITHOUT FOLDING\n",
    "print(find_optimal_k(new_X_train_with_pair_features, y_train, new_X_test_with_pair_features, y_test, 30, 'euclidean'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WITH FOLDING\n",
    "def get_new_features_with_fold(X, y, CNT_FOLDS = 3):\n",
    "    new_X = np.ndarray((X.shape[0], 3 * X.shape[1]))\n",
    "    for i in range(CNT_FOLDS):\n",
    "        ind = np.ndarray(((X.shape[0] + CNT_FOLDS - 1 - i) // CNT_FOLDS), dtype=int)\n",
    "        other_ind = np.ndarray(X.shape[0] - ind.shape[0], dtype=int)\n",
    "        cnt = 0\n",
    "        cnt_other = 0\n",
    "        for j in range(X.shape[0]):\n",
    "            if (j % CNT_FOLDS == i):\n",
    "                ind[cnt] = j\n",
    "                cnt += 1\n",
    "            else:\n",
    "                other_ind[cnt_other] = j\n",
    "                cnt_other += 1\n",
    "\n",
    "        count, successed = get_count_and_successed(X[other_ind, :], y[other_ind])\n",
    "        X_chunk_new = get_new_features(X[ind, :], count, successed)\n",
    "        new_X[ind, :] = X_chunk_new\n",
    "    return new_X\n",
    "\n",
    "CNT_FOLDS = 3\n",
    "new_X_train_with_pair_features = get_new_features_with_fold(X_train_with_pair_features, np.array(y_train, dtype=int), CNT_FOLDS)\n",
    "\n",
    "\n",
    "count, successed = get_count_and_successed(X_train_with_pair_features, np.array(y_train, dtype=int))\n",
    "new_X_test_with_pair_features = get_new_features(X_test_with_pair_features, count, successed)\n",
    "\n",
    "\n",
    "print(find_optimal_k(new_X_train_with_pair_features, y_train, new_X_test_with_pair_features, y_test, 30, 'euclidean'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Решающие деревья и леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Возьмите из предыдущей части выборку с парными признаками, преобразованную с помощью счетчиков без фолдинга. Настройте решающее дерево, подобрав оптимальные значения параметров `max_depth` и `min_samples_leaf`. Какой наилучший AUC-ROC на контроле удалось получить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ответы\n",
    "Весь код можно найти в файле: tree_question_1_and_2\n",
    "\n",
    "Оптимальные параметры:\n",
    "\n",
    "    max_depth = 20\n",
    "    \n",
    "    min_samples_leaf = 15\n",
    "    \n",
    "AUC: 0.780350343356\n",
    "\n",
    "<img src=\"tree.png\", width=200, align=left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Настройте случайный лес, подобрав такое число деревьев `n_estimators`, при котором ошибка выходит на асимптоту. Какое качество на тестовой выборке он дает?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ответы\n",
    "Весь код можно найти в файле: tree_question_1_and_2\n",
    "\n",
    "Эксперимент проводились при n_estimators = 1000\n",
    "\n",
    "AUC: 0.847733141114\n",
    "\n",
    "<img src=\"forest.png\", width=200, align=left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Возьмите выборку с парными признаками, для которой счетчики посчитаны с фолдингом. Обучите на ней случайный лес, подобрав число деревьев. Какое качество на тестовой выборке он дает? Чем вы можете объяснить изменение результата по сравнению с предыдущим пунктом?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ответы\n",
    "Весь код можно найти в файле: tree_question_3\n",
    "\n",
    "Эксперимент проводились при n_estimators = 1000\n",
    "\n",
    "AUC: 0.847844202625\n",
    "\n",
    "<img src=\"forest_with_folding.png\", width=200, align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При фолдинге небольшое преимущество, это связано с тем что фолдинг уменьшает вероятность переобучения. Оно такое незначительное, потому что лес также уменьшает вероятность переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = pd.read_csv('amazon.csv')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "\n",
    "max_value = 0\n",
    "for col_name in data.columns:\n",
    "    max_value = max(max_value, np.max(data[col_name]))\n",
    "print(max_value)\n",
    "\n",
    "def get_pair_features(X):\n",
    "    print(\"Begin\")\n",
    "    X_new = np.ndarray((X.shape[0], X.shape[1] * (X.shape[1] + 1) // 2))\n",
    "    X_new[:, 0:X.shape[1]] = copy.deepcopy(X.iloc[:])\n",
    "    print(\"End copy\")\n",
    "    len = X.shape[1]\n",
    "    for i in range(X.shape[1]):\n",
    "        print(\"Processing\", i, \"features\")\n",
    "        for j in range(i + 1, X.shape[1]):\n",
    "            X_new[:, len] = X.iloc[:, i] * 1000 * 1000 * 1000 + X.iloc[:, j] \n",
    "            len += 1\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_with_pair_features = get_pair_features(X_train)\n",
    "X_test_with_pair_features = get_pair_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_features(X, count, successed):\n",
    "    cnt = 0\n",
    "    new_X = np.ndarray((X.shape[0], 3 * X.shape[1]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            new_X[i, 3 * j] = count[j].get(X[i, j], 0)\n",
    "            new_X[i, 3 * j + 1] = successed[j].get(X[i, j], 0)\n",
    "            new_X[i, 3 * j + 2] =  round((new_X[i, 3 * j + 1] + 1) / (new_X[i, 3 * j] + 2), 4)\n",
    "            cnt += new_X[i, 3 * j] == 0;\n",
    "    print(cnt)\n",
    "    return new_X\n",
    "\n",
    "def get_count_and_successed(X_train, y_train):\n",
    "    count = [{} for i in range(X_train.shape[1])]\n",
    "    successed = [{} for i in range(X_train.shape[1])]\n",
    "    for col in range(X_train.shape[1]):\n",
    "        value, len = unique_with_count(X_train[:, col])\n",
    "        \n",
    "        count[col] = {cur_value: 0 for cur_value in value}\n",
    "        successed[col] = {cur_value: 0 for cur_value in value}\n",
    "        for ind in range(X_train.shape[0]):\n",
    "            count[col][X_train[ind, col]] += 1\n",
    "            successed[col][X_train[ind, col]] += (y_train[ind] == 1)\n",
    "        \n",
    "        for cur_value in value:\n",
    "            count[col][cur_value] /= y_train.shape[0]\n",
    "            successed[col][cur_value] /= y_train.shape[0]\n",
    "            successed[col][cur_value] = round(successed[col][cur_value], 3)\n",
    "    return (count, successed)\n",
    "\n",
    "def unique_with_count(input_array): # (value, count)\n",
    "    buf = copy.deepcopy(input_array)\n",
    "    buf = buf[buf == buf]\n",
    "    buf = np.sort(buf)\n",
    "    \n",
    "    Y = np.concatenate((buf[1:], np.array([np.nan])))\n",
    "    lens_seg = np.cumsum(np.ones(buf.shape[0]))\n",
    "    val = buf[buf != Y]\n",
    "    lens_seg = lens_seg[buf != Y]\n",
    "    lens_seg = np.asarray(np.concatenate((lens_seg[0:1], np.diff(lens_seg))), dtype = int)\n",
    "    return (val, lens_seg)\n",
    "\n",
    "def display_auc(y_true, y_predict):\n",
    "    print(\"AUC:\", sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true))\n",
    "    (fpr, tpr, thresholds) = sklearn.metrics.roc_curve(y_true=y_true, y_score=y_predict)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "\n",
    "def get_auc(y_true, y_predict):\n",
    "    return sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count, successed = get_count_and_successed(X_train_with_pair_features, np.array(y_train.iloc[:], dtype=int))\n",
    "new_X_train_with_pair_features = get_new_features(X_train_with_pair_features, count, successed)\n",
    "new_X_test_with_pair_features = get_new_features(X_test_with_pair_features, count, successed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_auc = 0\n",
    "max_max_depth = 0\n",
    "max_min_samples_leaf = 0\n",
    "max_y = None\n",
    "for max_depth in range(20, 30, 2):\n",
    "    for min_samples_leaf in range(10, 100, 5):\n",
    "        classifier = sklearn.tree.DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf )\n",
    "        classifier.fit(new_X_train_with_pair_features, np.array(y_train.iloc[:], dtype=int))\n",
    "        y = classifier.predict_proba(new_X_test_with_pair_features)\n",
    "        y = y[:, 1]\n",
    "\n",
    "        cur_auc = get_auc(y_true= y_test, y_predict = y)\n",
    "        if (max_auc < cur_auc):\n",
    "            max_auc = cur_auc\n",
    "            max_max_depth = max_depth\n",
    "            max_min_samples_leaf = min_samples_leaf\n",
    "            max_y = y\n",
    "        \n",
    "print(max_auc, max_max_depth, max_min_samples_leaf)\n",
    "display_auc(y_predict= max_y, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = sklearn.ensemble.RandomForestClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=15)\n",
    "classifier.fit(new_X_train_with_pair_features, y_train)\n",
    "y = classifier.predict_proba(new_X_test_with_pair_features)\n",
    "y = y[:, 1]\n",
    "display_auc(y_true=y_test, y_predict=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете поделиться своими мыслями о задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "С дотой задание прикольнее ;("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь вставьте смешную картинку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь посоветуйте преподавателям хороший фильм или сериал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Хранители"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
