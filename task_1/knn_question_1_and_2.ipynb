{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312153\n"
     ]
    }
   ],
   "source": [
    "max_value = 0\n",
    "for col_name in data.columns:\n",
    "    max_value = max(max_value, np.max(data[col_name]))\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_auc(y_true, y_predict):\n",
    "    print(\"AUC:\", sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true))\n",
    "    (fpr, tpr, thresholds) = sklearn.metrics.roc_curve(y_true=y_true, y_score=y_predict)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "\n",
    "def get_auc(y_true, y_predict):\n",
    "    return sklearn.metrics.roc_auc_score(y_score=y_predict, y_true=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#indicator 22 min\n",
    "neigh_with_indicator = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm='brute', metric=indicator)\n",
    "neigh_with_indicator.fit(X_train, y_train)\n",
    "y_with_indicator = neigh_with_indicator.predict_proba(X_test)\n",
    "\n",
    "y_with_indicator = y_with_indicator[:, 1]\n",
    "\n",
    "display_auc(y_true = y_test, y_predict = y_with_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_with_count(input_array): # (value, count)\n",
    "    buf = copy.deepcopy(input_array)\n",
    "    buf = buf[buf == buf]\n",
    "    buf = np.sort(buf)\n",
    "    \n",
    "    Y = np.concatenate((buf[1:], np.array([np.nan])))\n",
    "    lens_seg = np.cumsum(np.ones(buf.shape[0]))\n",
    "    val = buf[buf != Y]\n",
    "    lens_seg = lens_seg[buf != Y]\n",
    "    lens_seg = np.asarray(np.concatenate((lens_seg[0:1], np.diff(lens_seg))), dtype = int)\n",
    "    return (val, lens_seg)\n",
    "\n",
    "\n",
    "p_2 = np.zeros((X_train.shape[1], max_value + 1))\n",
    "p = np.zeros((X_train.shape[1], max_value + 1))\n",
    "f = np.zeros((X_train.shape[1], max_value + 1))\n",
    "for col in range(X_train.shape[1]):\n",
    "    (unique_value, count) = unique_with_count(X_train.iloc[:, col])\n",
    "    cur_f = count\n",
    "    cur_p = (count + 0.0) / X_train.shape[0]\n",
    "    cur_p_2 = count * (count - 1.0) / X_train.shape[0] / (X_train.shape[0] - 1)\n",
    "    sum_p_2 = np.zeros(unique_value.shape[0])\n",
    "    for i in range(unique_value.shape[0]):\n",
    "        sum_p_2[i] = np.sum(cur_p_2[cur_p < cur_p[i]])\n",
    "    \n",
    "    f[col][unique_value] = cur_f\n",
    "    p[col][unique_value] = cur_p\n",
    "    p_2[col][unique_value] = sum_p_2\n",
    "    \n",
    "log_f = np.log(f + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smoothed_indicator(x, y, **kwargs):\n",
    "    buf = kwargs['p_2']\n",
    "    return np.sum((x != y) + (x == y) * buf[:, np.asarray(x, int)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#smoothed_indicator\n",
    "neigh_with_smoothed_indicator = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm='brute', metric=smoothed_indicator, \n",
    "                                                                       metric_params={'p_2': p_2})\n",
    "neigh_with_smoothed_indicator.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_with_smoothed_indicator = neigh_with_smoothed_indicator.predict_proba(np.asarray(X_test, int))\n",
    "y_with_smoothed_indicator = y_with_smoothed_indicator[:, 1]\n",
    "\n",
    "display_auc(y_true = y_test, y_predict = y_with_smoothed_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_indicator(x, y, **kwargs):\n",
    "    buf = kwargs['log_f']\n",
    "    return np.sum((x != y) * buf[:, np.asarray(x, int)] * buf[:, np.asarray(y, int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#log_indicator\n",
    "neigh_with_log_indicator = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm='brute', \n",
    "                                                              metric=log_indicator,\n",
    "                                                             metric_params={'log_f': log_f})\n",
    "neigh_with_log_indicator.fit(X_train, y_train)\n",
    "y_with_log_indicator = neigh_with_log_indicator.predict_proba(np.asarray(X_test, int))\n",
    "\n",
    "y_with_log_indicator = y_with_log_indicator[:, 1]\n",
    "display_auc(y_true = y_test, y_predict = y_with_log_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_k(X_train, y_train, X_test, y_test, MAXK, metric, metric_params = None):\n",
    "    MAXK += 1\n",
    "    classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=MAXK, \n",
    "                                                        algorithm='brute', \n",
    "                                                        metric=metric,\n",
    "                                                        metric_params=metric_params)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    nearest_class = classifier.kneighbors(X_test, return_distance=0)\n",
    "    precision = np.ndarray((MAXK, X_test.shape[0], 2))\n",
    "    for ind_object in range(X_test.shape[0]):\n",
    "        histohram = np.zeros(2)\n",
    "        for k in range(0, MAXK):\n",
    "            histohram[y_train.iloc[nearest_class[ind_object][k]]] += 1\n",
    "            precision[k, ind_object] = histohram / (k + 1)\n",
    "    \n",
    "    max_auc = 0.0\n",
    "    max_k = 0;\n",
    "    for k in range(0, MAXK):\n",
    "        y_predict = precision[k, :, 1]\n",
    "        cur_auc = get_auc(y_true = y_test, y_predict = y_predict)\n",
    "        if (cur_auc > max_auc):\n",
    "            max_auc = cur_auc\n",
    "            max_k = k + 1\n",
    "        \n",
    "    return (max_auc, max_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( find_optimal_k(X_train, y_train, X_test, y_test, 15, log_indicator, metric_params={'log_f': log_f}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( find_optimal_k(X_train, y_train, X_test, y_test, 15, smoothed_indicator, metric_params={'p_2': p_2}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( find_optimal_k(X_train, y_train, X_test, y_test, 15, indicator) )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
